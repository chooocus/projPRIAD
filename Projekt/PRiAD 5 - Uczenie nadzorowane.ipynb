{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRiAD 4\n",
    "\n",
    "# Uczenie nadzorowane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasyfikacja zalicza się do metod uczenia nadzorowanego (ang. supervised learning). Zbiór (macierz) danych w tym przypadku składa się z obiektów charakteryzujących się atrybutami opisującymi i atrybutem decyzyjnym. Przyjmuje się przy tym, że pomiędzy atrybutami opisującymi, a atrybutem decyzyjnym zachodzi pewien związek przyczynowo-skutkowy zaś kategoryczny atrybut decyzyjny określa klasę do której przynależy obiekt. Zbiór danych jest traktowany jako źródło wiedzy na podstawie którego określa się rodzaj klasyfikatora, a następnie dobiera jego parametry w tzw. procesie uczenia. Gotowy klasyfikator może następnie zostać wykorzystany do określenia przynależności do właściwej klasy (nowego) obiektu dla którego znane są jedynie wartości atrybutów opisujących. \n",
    "\n",
    "Z reguły w celu sprawdzenia poprawności danego algorytmu i sprawdzenia jego skuteczności dla danego zadania klasyfikacji podział zbioru danych wykonywany jest na zbiór uczący i testowy (najczęściej w proporcjach 80/20 lub 70/30).\n",
    "\n",
    "W ćwiczeniu pokazane zostaną następujące metody klasyfikacji:\n",
    "1. Metoda najbliżego sąsiada \n",
    "2. Metoda k-najbliższych sąsiadów\n",
    "3. Metoda najbliższego prototypu\n",
    "4. Naiwny klasyfikatory Bayesa\n",
    "5. Drzewa decyzyjne\n",
    "\n",
    "Na początek jednak, tradycyjnie, zostaną wczytane niezbędne pakiety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# zmiana sposobu wyświetlania danych typu float\n",
    "pd.options.display.float_format = \"{:.2f}\".format "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodatkowo, wczytane zostaną procedury niezbędne do realizacji zadań klasyfikacji z pakietu `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Klasyfikator najbliższego sąsiada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zasadą działania metod najbliższego sąsiada (1-NN) jest poszukiwanie najbliższego sąsiada dla nowego obiektu o nieznanej klasie, wśród obiektów znajdujących się w zbiorze uczącym. Klasa, do której najbliższy sąsiad przynależy jest przypisywana klasyfikowanemu obiektowi. Poniższy przykład pokazuje wyszukiwanie najbliższych sąsiadów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'dane1.csv' does not exist: b'dane1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9370fe1942b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dane1.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'atrybut1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'atrybut2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"klasa\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnbrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ball_tree'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnbrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'atrybut1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'atrybut2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'dane1.csv' does not exist: b'dane1.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dane1.csv')\n",
    "df.describe()\n",
    "plt.scatter(df.loc[:, 'atrybut1'], df.loc[:, 'atrybut2'], c=df[\"klasa\"].astype('category').cat.codes, marker = '.')\n",
    "nbrs = NearestNeighbors(n_neighbors=3, algorithm='ball_tree')\n",
    "nbrs.fit(df[['atrybut1','atrybut2']])\n",
    "distances, indices = nbrs.kneighbors(df[['atrybut1','atrybut2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nbrs_wynik = pd.DataFrame({'atrybut1':df.loc[:, 'atrybut1'],\n",
    "                           'atrybut2':df.loc[:, 'atrybut2'],\n",
    "                           'Najbliższy': indices[:,1],\n",
    "                           'Odlegość od najbl.': distances[:,1],\n",
    "                           'Drugi najbl.': indices[:,2],\n",
    "                           'Odlegość od drugiego': distances[:,2]})\n",
    "nbrs_wynik.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Pytanie** Czy relacja \"x jest najbliższym sąsiadem y\" jest symetryczna ? Zastanów się czy tak jest i sprawdź w powyższych wyniakach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W przypadku pojedynczego zbioru danych, w celu sprawdzenia działania (każdego) klasyfikatora, należy podzielić zbiór danych na uczący i testowy. W tym celu wykorzystuje się funkcję `train_test_split`. Funkcja ta zarówno na wejściu jak i na wyjściu wymaga podania osobno atrybutów opisujących i atrybutu decyzyjnego. Taki sposób reprezentacji będzie wykorzystywany dalej przez funkcje realizujące zadania klasyfikacji. Dla ułatwienia przygotowana została funkcja realizująca podział zbioru i zapisująca zbiór uczący i testowy w jednej strukturze (słowniku)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def podziel(df,proporcja):\n",
    "    # dzieli macierz (ramkę) danych na zbiór uczacy i testowy\n",
    "    # df - ramka danych; proporcja - proporcja podzialu (0-1)\n",
    "    # zwraca słownik z kluczami:\n",
    "    # opis_ucz/opis_test - macierz atrybutów opisujących zbioru uczącego/testowego\n",
    "    # dec_ucz/dec_test - wektor wartosci atrybutu decyzyjnego zbioru uczącego/testowego\n",
    "    # uwaga: atrybut opisujący jest zawsze na końcu (ostatnia kolumna ramki)\n",
    "    opis_ucz, opis_test, dec_ucz, dec_test = train_test_split(df.iloc[:,0:-1], df.iloc[:,-1].astype('category').cat.codes, test_size=proporcja)#, random_state=0)\n",
    "    return {\"opis_ucz\":opis_ucz, \"opis_test\":opis_test, \"dec_ucz\":dec_ucz, \"dec_test\":dec_test}\n",
    "\n",
    "dane = podziel(df,0.3)\n",
    "print('Liczba obiektów zbioru uczącego: ', len(dane[\"opis_ucz\"]))\n",
    "print('Liczba obiektów zbioru testowego: ', len(dane[\"opis_test\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie zostanie utworzony model klasyfikatora najbliższego sąsiada. Do tego celu wykorzystana zostanie funkcja `KNeighborsClassifier`, której parametr *n_neighbors* określa zadaną liczbę sąsiadów - w tym przypadku równą 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jakość klasyfikacji można oceniać przy pomocy np. macierzy pomyłek (zwanej także macierzą kontyngencji lub tabelą krzyzową), która zawiera informacje o liczbie obiektów przypisanych do klas przez wybrany model klasyfikatora dla poszczególnych wartosci atrybutu decyzyjnego. Macierz taką wyznacza się zarówno dla zbioru uczącego jak i dla zbioru testowego. Procedura `weryfikuj` wyświetla macierze pomyłek dla obu zbiorów. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weryfikuj(model,dane,atryb):\n",
    "    # wyswietla wynik weryfikacji klasyfikatora w postaci macierzy pomyłek\n",
    "    # dla zbioru uczącego i testowego\n",
    "    # model - model klasyfikatora\n",
    "    # dane - dane (słownik zwracany przez funkcje podziel)\n",
    "    # atryb - lista atrybutów uwzględnianych w weryfikacji\n",
    "    model.fit(dane[\"opis_ucz\"].iloc[:,atryb], dane[\"dec_ucz\"])\n",
    "    wynik_ucz = model.predict(dane[\"opis_ucz\"].iloc[:,atryb])\n",
    "    wynik_test = model.predict(dane[\"opis_test\"].iloc[:,atryb])\n",
    "    print(\"Macierz pomyłek dla zbioru uczącego\")\n",
    "    print(pd.crosstab(dane[\"dec_ucz\"],wynik_ucz)) \n",
    "    print(\"Macierz pomyłek dla zbioru testowego\")\n",
    "    print(pd.crosstab(dane[\"dec_test\"],wynik_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Badanie klasyfikatora wymaga wykonania następującej sekwencji czynności:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wczytanie badanego zbioru danych\n",
    "df = pd.read_csv('dane1.csv')\n",
    "print(df.info())\n",
    "# \n",
    "#sns.pairplot(df, kind=\"scatter\", hue = \"klasa\")\n",
    "#plt.show()\n",
    "\n",
    "# podział zbioru danych\n",
    "d = podziel(df,0.3)\n",
    "# zdefiniowanie modelu klasyfikatora\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "# weryfikacja\n",
    "weryfikuj(model,d,[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wynik testu dla zbioru uczącego w przypadku klasyfikatora 1-NN jest oczywisty, niezależnie od danych wejściowych. Jak będzie się można przekonać w dalszej części ćwiczenia, nie będzie to juz takie oczywiste dla innych klasyfikatorów i zbiorów danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Granice decyzyjne oddzielaja obszary w przestrzeni atrybutów, które odpowiadaja poszczególnym klasom. Sposób podziału przestrzeni atrybutów zalezy przy tym od rodzaju klasyfikatora. Poniewaz granice decyzyjne mogą być czytelnie uwidocznione na wykresie punktowym dwuwymiarowym. W przypadku wiekszej liczby takich atrybutów nalezy\n",
    "wiec wybrac dwa sposród nich i dla niech przeprowadzic operacje wyznaczania i wizualizacji granic decyzyjnych. Do wizualizacji granic decyzyjnych została przygotowana procedura `granice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def granice(model,dane,atr_x, atr_y,tytul,kontur = 1):\n",
    "    # wyswietla granice decyzyjne\n",
    "    # model - model klasyfikatora\n",
    "    # dane - dane (słownik zwracany przez funkcje podziel)\n",
    "    # atr_x/atr_y - artybut wyswietlany na osi x/y\n",
    "    # tytul - wyswietlany tytul wykresu\n",
    "    # kontur - par. opcjonalny (=0 -> brak konturu)\n",
    "    if (kontur == 1):    \n",
    "        model.fit(dane[\"opis_ucz\"].iloc[:,[atr_x,atr_y]], dane[\"dec_ucz\"])\n",
    "        x_min = min(dane[\"opis_ucz\"].iloc[:, atr_x].min(),dane[\"opis_test\"].iloc[:, atr_x].min())\n",
    "        x_max = max(dane[\"opis_ucz\"].iloc[:, atr_x].max(),dane[\"opis_test\"].iloc[:, atr_x].max())\n",
    "        y_min = min(dane[\"opis_ucz\"].iloc[:, atr_y].min(),dane[\"opis_test\"].iloc[:, atr_y].min())\n",
    "        y_max = max(dane[\"opis_ucz\"].iloc[:, atr_y].max(),dane[\"opis_test\"].iloc[:, atr_y].max())\n",
    "        rozst_x = x_max - x_min\n",
    "        rozst_y = y_max - y_min\n",
    "        x_min = x_min - 0.1*rozst_x\n",
    "        x_max = x_max + 0.1*rozst_x\n",
    "        y_min = y_min - 0.1*rozst_y\n",
    "        y_max = y_max + 0.1*rozst_y       \n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, (x_max-x_min)/150),\n",
    "                     np.arange(y_min, y_max, (y_max-y_min)/150))\n",
    "        Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "    plt.figure(dpi = 100)\n",
    "    plt.title(tytul)\n",
    "    if (kontur == 1):\n",
    "        plt.contourf(xx, yy, Z, levels = 4, alpha=0.2)\n",
    "    plt.scatter(dane[\"opis_ucz\"].iloc[:, atr_x], dane[\"opis_ucz\"].iloc[:, atr_y], c=dane[\"dec_ucz\"], marker = '.')\n",
    "    plt.scatter(dane[\"opis_test\"].iloc[:, atr_x], dane[\"opis_test\"].iloc[:, atr_y], c=dane[\"dec_test\"], marker = 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wizualizacja granic decyzyjnych ułatwia analizę klasyfikatora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nazwa_pliku = 'dane1.csv'\n",
    "# wczytanie badanego zbioru danych\n",
    "df = pd.read_csv(nazwa_pliku)\n",
    "# podział zbioru danych\n",
    "d = podziel(df,0.3)\n",
    "# zdefiniowanie modelu klasyfikatora\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "# wybór atrybutów\n",
    "ax, ay = 0,1\n",
    "# granice dycyzyjne\n",
    "granice(model,d,ax,ay,\"klasyfikator 1-NN dla zbioru \" + nazwa_pliku)\n",
    "# weryfikacja\n",
    "weryfikuj(model,d,[ax,ay])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Zadanie** Czy wyniki dla zbioru `dane2` są lepsze czy gorsze niz dla `dane1`? Zastanów się, dzlaczego ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miejsce na kod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Zadanie** Poeksperymentuj w analogiczny sposób z pozostałymi macierzami `dane`, w tym także ze zbiorem `iris`. Ocen przydatność klasyfikatora dla każdego zbioru danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miejsce na kod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedura `granice` umożliwia także wyświetlenie wykresów punktowych danych z podziałem na zbiór testowy i uczący bez wyświetlania granic decyzyjnych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nazwa_pliku = 'dane1.csv'\n",
    "df = pd.read_csv(nazwa_pliku)\n",
    "d = podziel(df,0.3)\n",
    "granice(0,d,0,1,\"\",0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Zadanie** Wykonaj powyższy kod kilkukrotnie. Czy widzisz jakieś różnice między wynikami kolejnych wywołań ? Dlaczego ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Klasyfikator $k$-najbliższych sąsiadów (k-NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasyfikator $k$-najbliższych sąsiadów jest uoglnieniem klasyfikatora najbliższego sąsiada. W jego przypadku, na podstawie znanych klasy do której należy ustalona liczba $k$ najbliższych sąsiadów określana jest przynalezność klasyfikowanego obiektu do klasy. Klasa wynikowa odpowiada klasie dominującej w zbiorze $k$-najbliżsych sąsiadów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Zadanie** Jak zwiększenie liczby sąsiadów wpłynie na wynik klasyfikacji zbioru `dane2` ? Dlaczego ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miejsce na kod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analiza wpływu liczby $k$ na wynik klasyfikacji na przykładzie zbioru `dane3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nazwa_pliku = 'dane3.csv'\n",
    "df = pd.read_csv(nazwa_pliku)\n",
    "d = podziel(df,0.3)\n",
    "for k in [1,3,5,9]:\n",
    "    model_knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    granice(model_knn,d,0,1,\"klasyfikator \" + str(k)+ \"-NN dla zbioru \" + nazwa_pliku)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Zadanie** Poeksperymentuj w analogiczny sposób z pozostałymi macierzami danych. Ocen\n",
    "przydatnosc klasyfikatora dla kazdego zbioru danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miejsce na kod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W celu doboru właściwej (na ogół nieparzystej) ilości sąsiadów należy wykonać analizę błędu klasyfikacji dla różnych wartości sąsiadów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nazwa_pliku = 'dane2.csv'\n",
    "df = pd.read_csv(nazwa_pliku)\n",
    "d = podziel(df,0.3)\n",
    "granice(model,d,0,1,\"\",0)\n",
    "kvals = range(1, 16)\n",
    "rss_all = np.zeros(15)\n",
    "for k in kvals:\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(d['opis_ucz'],d['dec_ucz'])\n",
    "    predictions = model.predict(d['opis_test'])\n",
    "    rss_all[k-1] = 1-model.score(d['opis_test'],d['dec_test'])\n",
    "plt.figure(dpi=90)\n",
    "plt.plot(kvals, rss_all,'bo-')\n",
    "plt.title('Wykres bledu')\n",
    "plt.xlabel('Liczba sasiadow')\n",
    "plt.ylabel('Prawdopodobienstwo bledu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Zadanie** Jak na podstawie powyższego wykresu określić optymalną liczbę sąsiadów ? Jak przebiega ten wykres dla różnych zbiorów danych (porównaj m.in. `dane2` i `dane3`) ? Skąd się biorą różnice w jego przebiegu ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miejsce na kod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Zadanie** Dobierz optymalną liczbę $k$ dla innych zbiorów "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miejsce na kod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Metoda najbliższych prototypów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wadą wszystkich opisanych do tej pory klasyfikatorów najbliższych sąsiadów jest konieczność korzystania podczas procesu klasyfikacji z całego zbioru uczącego. Dla duzej liczby obiektów zbioru uczącego i dużej liczby cech proces klasyfikacji staje się czasochłonny, czesto zachodzi ponadto koniecznosc przechowywania całego tego zbioru w pamieci. Rozwiazaniem tego problemu jest redukcja zbioru uczacego do zbioru składajacego sie z obiektów reprezentatywnych dla kazdej z rozpatrywanych klas – prototypów klas. Wówczas, zamiast rozpatrywania całego zbioru uczacego, rozpatrywany jest jedynie zbiór prototypów.\n",
    "Typowym rozwiazaniem jest wybór po jednym prototypie na klasę, choc stosowane jest takze rozwiazanie polegajace na wyborze wiekszej liczby prototypów kazdej klasy. Prototyp jest charakteryzowany przez wartosci jego atrybutów. Wartosci te sa wyznaczane najczesciej jako miary tendencji centralnej wyznaczane dla wszystkich obiektów w danej klasie. Najczesciej stosowana miara jest tu średnia arytmetyczna. Podzbiory danych odpowiadające poszczególnym klasom są w tym przypadku zastępowane przez centroidy klas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nazwa_pliku = 'dane1.csv'\n",
    "# wczytanie badanego zbioru danych\n",
    "df = pd.read_csv(nazwa_pliku)\n",
    "# podział zbioru danych\n",
    "d = podziel(df,0.3)\n",
    "# zdefiniowanie modelu klasyfikatora\n",
    "model = NearestCentroid()\n",
    "# granice dycyzyjne\n",
    "granice(model,d,0,1,\"Najbliższego prototypu dla zbioru \" + nazwa_pliku)\n",
    "# weryfikacja\n",
    "weryfikuj(model,d,[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Zadanie** Poeksperymentuj w analogiczny sposób z pozostałymi macierzami `dane`, w tym także ze zbiorem `iris`. Ocen przydatność klasyfikatora dla każdego zbioru danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miejsce na kod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Pytania** \n",
    "1. Czy w przypadku klasyfikatora najblizszych prototypów zachodzi faza uczenia ? Jesli tak, to na czym polega ?\n",
    "2. Jak zmierzyc stopien rozproszenia wartosci atrybutu wokół wartosci sredniej ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Zadanie**  Wykonaj klasyfikacje klasyfikatorem $k$-NN, dla różnych wartości $k$ oraz najblizszych prototypów. Wykonaj weryfikacje wyników klasyfikacji na zbiorze uczacym i testowym dla kazdego z trzech klasyfikatorów. Ocen wyniki. Zastanów sie jak zinterpretowac błedne wskazania klasyfikatora dla obiektów ze zbioru uczacego ? Dlaczego moze sie zdarzyc, ze nie wszystkie obiekty zbioru uczacego sa poprawnie klasyfikowane? Na wykresie punktowym wskaz takie obiekty. Czy – w tym konkretnym przypadku – niepoprawna klasyfikacja jest efektem pozytywnym czy negatywnym ? O jakiej własnosci klasyfikatora ona swiadczy ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miejsce na kod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Naiwny klasyfikator Bayesa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podstawa klasyfikacji Bayesowskiej jest twierdzenie Bayesa, które dotyczy prawdopodobienstw warunkowych. W przypadku klasyfikacji, zdarzenia losowe, które sa brane pod uwage przy wyznaczaniu prawdopodobienstw dotycza dwóch faktów zwiazanych z rozpoznawanymi obiektami: posiadania przez obiekt konkretnego zbioru wartosci atrybutów opisujacych zapisanego zwykle w formie wektora wartosci atrybutów oraz przynaleznosci tego obiektu do poszczególnych klas. Przynaleznosc obiektu do poszczególnych klas jest okreslana przy pomocy funkcji dyskryminacyjnych. i-ta funkcja dyskryminacyjna dla obiektu o wektorze atrybutów opisujacych\n",
    "jest w tym przypadku tozsama prawdopodobienstwu warunkowemu przynależnosci obiektu do i-tej klasy pod warunkiem posiadania przez obiekt wektora atrybutów opisujacych. Wygodnym załozeniem jest brak zaleznosci miedzy poszczególnymi atrybutami opisujacymi.\n",
    "Dzieki niemu mozna przyjać, ze zdarzenia losowe polegajace na posiadaniu przez obiekt konkretnych wartosci poszczególnych atrybutów sa od siebie niezalezne. Klasyfikatory spełniajace to załozenie noszą nazwę naiwnych klasyfikatorów Bayesowskich. W przypadku atrybutów ilościowych niezbędne prawdopodobieństwa szacuje sie z wykorzystaniem typowych rozkładów zmiennych losowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nazwa_pliku = 'dane1.csv'\n",
    "# wczytanie badanego zbioru danych\n",
    "df = pd.read_csv(nazwa_pliku)\n",
    "# podział zbioru danych\n",
    "d = podziel(df,0.3)\n",
    "# zdefiniowanie modelu klasyfikatora\n",
    "model = GaussianNB()\n",
    "# granice dycyzyjne\n",
    "granice(model,d,0,1,\"klasyfikator Bayesa dla zbioru \" + nazwa_pliku)\n",
    "# weryfikacja\n",
    "weryfikuj(model,d,[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Zadanie** Wykonaj klasyfikacje klasyfikatorem Bayesa wszystkich zbiorów, dla których wyniki klasyfikacji najblizszego prototypu były niezadowalajace. Czy zastosowanie klasyfikatora\n",
    "Bayesa je polepsza ? Dlaczego ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kod zadania\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Zadanie** Znajdz zbiory danych, w przypadku których wyniki klasyfikacji Bayesowskiej są gorsze niz $k$-NN. Zastanów sie dlaczego tak sie dzieje. Dla jakich dystrybucji obiektów w przestrzeni atrybutów (połozenia zbiorów punktów na wykresie punktowym) klasyfikator Bayesa daje dobre wyniki, a dla jakich gorsze\n",
    "? Dlaczego ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kod zadania\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Zadanie** Poeksperymentuj z pozostałymi macierzami danych. Oceń przydatnosc klasyfikatora dla każdego zbioru danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kod zadania\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Drzewa decyzyjne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drzewa decyzyjne sa struktura grafowa przedstawiajaca zaleznosci miedzy atrybutami obiektów. Drzewo decyzyjne opisuje w formie grafu zaleznosc wartosci atrybutu decyzyjnego od wartosci atrybutów\n",
    "opisujacych. Dzieki hierarchicznej reprezentacji tych zaleznosci drzewo nie tylko jest klasyfikatorem, ale takze umozliwia analize istotnosci poszczególnych atrybutów dla konkretnego\n",
    "procesu klasyfikacji. Czestym problemem przy klasyfikacji za pomoca drzew jest przetrenowanie. Nie zawsze stuprocentowo skuteczna klasyfikacja zbioru uczacego przekłada sie na dobre wyniki klasyfikacji\n",
    "zbioru testowego, poniewaz drzewo, w którym jest zbyt wiele zbyt szczegółowych testów traci zdolnosc generalizacji. Problem przetrenowania moze byc rozwiazany na dwa sposoby,\n",
    "poprzez:\n",
    "* wstrzymanie budowy drzewa, zanim osiagnie maksymalne rozmiary (ograniczanie w\n",
    "trakcie rozrostu), lub\n",
    "* przycinanie drzewa po jego wyznaczeniu (drzewa maksymalnego)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nazwa_pliku = 'dane1.csv'\n",
    "# wczytanie badanego zbioru danych\n",
    "df = pd.read_csv(nazwa_pliku)\n",
    "# podział zbioru danych\n",
    "d = podziel(df,0.3)\n",
    "# zdefiniowanie modelu klasyfikatora\n",
    "model = tree.DecisionTreeClassifier(max_depth=4)\n",
    "# granice dycyzyjne\n",
    "granice(model,d,0,1,\"drzewo decyzyjne dla zbioru \" + nazwa_pliku)\n",
    "# weryfikacja\n",
    "weryfikuj(model,d,[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drzewa decyzyjne o różnych głębokościach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nazwa_pliku = 'dane2.csv'\n",
    "# wczytanie badanego zbioru danych\n",
    "df = pd.read_csv(nazwa_pliku)\n",
    "# podział zbioru danych\n",
    "d = podziel(df,0.3)\n",
    "for g in [2,3,4,5,6]:\n",
    "    drzewo = tree.DecisionTreeClassifier(max_depth=g)\n",
    "    tekst = \"drzewo o głębokości \" + str(g) + \" dla zbioru \" + nazwa_pliku\n",
    "    granice(drzewo ,d,0,1,tekst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Zadanie** Utwórz drzewa decyzyjne dla innych zbiorów danych. Ocen przydatnosc klasyfikatora dla kazdego zbioru danych. Dla jakich danych konstrukcja drzew jest prostsza, a dla jakich – bardziej skomplikowana ? Dlaczego ? Jak wielkosc drzewa wpływa na skutecznosc klasyfikacji ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kod zadania\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Zadanie** Poeksperymentuj z roznymi klasyfikatorami na zbiorze `iris` o czterech atrybutach decyzyjnych, wybierajac tylko dwa z nich. Zwróc uwage na to jak wybór dwóch z czterech atrybutów wpływa na wynik klasyfikacji. Wskaz najlepsza i najgorsza pare atrybutów z punktu widzenia poprawnosci klasyfikacji. Czy jestes w stanie wskazac na macierzy wykresów punktowych dla tego zbioru danych, cechy rozkładu punktów, które potwierdzaja ten wybór ? Porównaj wynik klasyfikacji dla najlepszej pary atrybutów z klasyfikacja z wykorzystaniem wszystkich czterech atrybutów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kod zadania\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Zadanie** Przeanalizuj zbiór `dane20.csv`. Wykonaj stosowną wyzializację danych. Określ, które atrybuty mają wpływ na przynależność obiektu do klasy, a które - nie. Przetestuj omówione klasyfikatory wykorzystując w klasyfikacji: \n",
    "1. wszystkie atrybuty\n",
    "2. atrybuty wpływające na klasę obiektu\n",
    "3. atrybuty niewpływające na klasę \n",
    "4. dowolną mieszankę obu rodzajów atrybutów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kod zadania\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
